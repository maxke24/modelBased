{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b89a117-7ef5-43a4-833b-ee8b064d9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stops = pd.read_csv('gtfs_data/stops.csv')\n",
    "# Load translations from csv\n",
    "translations = pd.read_csv('gtfs_data/translations.csv')\n",
    "stop_times = pd.read_csv('gtfs_data/stop_times.csv')\n",
    "routes = pd.read_csv('routes_with_data.csv')\n",
    "\n",
    "# Merge stops DataFrame with translations DataFrame on stop_id\n",
    "stops_with_translations = stops.merge(translations, left_on='stop_name', right_on='field_value', how='left')\n",
    "stops_with_translations['stop_name'] = stops_with_translations['translation']\n",
    "\n",
    "stops_with_translations = stops_with_translations[stops_with_translations['language'] == 'nl']\n",
    "\n",
    "# Remove rows with non-numeric stop_id\n",
    "stops_with_translations = stops_with_translations[stops_with_translations['stop_id'].astype(str).str.isdigit()]\n",
    "stop_times = stop_times[stop_times['stop_id'].astype(str).str.isdigit()]\n",
    "\n",
    "stops_with_translations['stop_id'] = stops_with_translations['stop_id'].astype(str)\n",
    "stop_times['stop_id'] = stop_times['stop_id'].astype(str)\n",
    "\n",
    "stops_temp = stops_with_translations.merge(stop_times, on='stop_id', how='left')\n",
    "stops_trip = stops_temp.merge(routes, on='trip_id', how='left')\n",
    "\n",
    "# stops_trip = stops_with_translations.merge(stop_times, on='stop_id', how='left')\n",
    "# stops_trip['from'] = stops_trip['trip_id'].str.split(':').str[3]\n",
    "# stops_trip['to'] = stops_trip['trip_id'].str.split(':').str[4]\n",
    "\n",
    "stops_no_dup = stops_trip[['stop_id', 'stop_name', 'route_id', 'stop_sequence', 'trip_id']].drop_duplicates()\n",
    "stops_no_dups = stops_no_dup.dropna(subset=['route_id'], inplace=False).drop_duplicates()\n",
    "# Create a CLINGO file with unique stops predicate\n",
    "with open(\"stops.lp\", \"w\") as f:\n",
    "    for index, row in stops_no_dup.iterrows():\n",
    "        if pd.isna(row['stop_name']):\n",
    "            continue  # Skip rows where no translation was found\n",
    "        if({str(row['route_id']).split('.')[0]}):\n",
    "            f.write(f'''stops(\"{row['trip_id']}\", {row['stop_id']}, \"{row['stop_name'].lower()}\", {row['stop_sequence']}).\\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dc8c1-ac82-49be-ba85-5e8673d163fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_with_translations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9e19e-f6b7-4bbc-889d-81855f4858a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e0fc63-57b3-4e10-9071-a2dd125dea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_no_dup = stops_no_dup.dropna(subset=['route_id'], inplace=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d65bfc-1f46-4647-abae-837470b322df",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23509c57-b6ce-4d2f-b2e2-4c81baf4572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_no_dup.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c86c54-f82a-43aa-9f7b-568eec1e6dc3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx import DiGraph\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Function to create a graph for each route\n",
    "def create_graph_for_route(route_data):\n",
    "    G = DiGraph()\n",
    "    for _, row in route_data.iterrows():\n",
    "        stop_id = row['stop_id']\n",
    "        place = row['stop_sequence']\n",
    "        route = str(row['route_id']).split('.')[0]\n",
    "        if not G.has_node(stop_id):\n",
    "            G.add_node(stop_id)\n",
    "        G.nodes[stop_id]['label'] = row['stop_name']\n",
    "        if place > 1:\n",
    "            prev_stop_id = route_data.loc[route_data['stop_sequence'] == place - 1, 'stop_id'].values\n",
    "            if len(prev_stop_id) > 0:\n",
    "                G.add_edge(prev_stop_id[0], stop_id)\n",
    "    return G\n",
    "\n",
    "# Check if stops_no_dup is empty\n",
    "if stops_no_dup.empty:\n",
    "    print(\"stops_no_dup is empty\")\n",
    "else:\n",
    "    # Group the DataFrame by route_id and create a graph for each route\n",
    "    graphs = {}\n",
    "    for route_id, route_data in stops_no_dup.groupby('route_id'):\n",
    "        if len(route_data) == 0:\n",
    "            print(f\"Group {route_id} is empty\")\n",
    "        else:\n",
    "            graphs[route_id] = create_graph_for_route(route_data)\n",
    "\n",
    "    # Combine all graphs into one large graph using nx.compose_all\n",
    "    large_graph = nx.compose_all(graphs.values())\n",
    "\n",
    "# Convert the NetworkX graph to a Plotly graph\n",
    "pos = nx.kamada_kawai_layout(large_graph)  # positions for all nodes\n",
    "\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "\n",
    "for edge in large_graph.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "\n",
    "# Assuming 'stop_id' is the label you want to use\n",
    "for node in large_graph.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers+text',\n",
    "    hoverinfo='text',\n",
    "    text=[f\"{str(large_graph.nodes[node]['label']).capitalize()}<br>{large_graph.degree(node)} connections\" for node in large_graph.nodes()],\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        line_width=2))\n",
    "\n",
    "# Create a color list for edges\n",
    "edge_colors = ['black'] * len(large_graph.edges())\n",
    "\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                 title='<br>Network graph',\n",
    "                 titlefont_size=16,\n",
    "                 showlegend=False,\n",
    "                 hovermode='closest',\n",
    "                 margin=dict(b=20,l=5,r=5,t=40),\n",
    "                 xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                 yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "\n",
    "# Node ID you want to autozoom into\n",
    "target_node = '8891702'\n",
    "\n",
    "if target_node in pos:\n",
    "    # Get the coordinates of the target node\n",
    "    x_target, y_target = pos[target_node]\n",
    "    \n",
    "    # Create a figure with the edges and nodes\n",
    "    fig = go.Figure(data=[edge_trace, node_trace])\n",
    "    \n",
    "    # Update layout to center on the target node and adjust zoom level\n",
    "    fig.update_layout(\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        title_text=f'Network graph autozoomed into Node {target_node}',\n",
    "        scene=dict(\n",
    "            camera=dict(eye=dict(x=-1.25, y=-1.25, z=0.7)),\n",
    "            xaxis_title='X-axis',\n",
    "            yaxis_title='Y-axis',\n",
    "            zaxis_title='Z-axis'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adjust the layout to center on the target node\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            camera=dict(eye=dict(x=-1.25, y=-1.25, z=0.7)),\n",
    "            xaxis=dict(range=[x_target - 1, x_target + 1]),\n",
    "            yaxis=dict(range=[y_target - 1, y_target + 1])\n",
    "        )\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(f\"Target node '{target_node}' not found in the graph.\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267eb112-30b2-4ef9-8b1d-e49a8c3eec6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d636f2-6a82-409b-8ae3-71739f3f425d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "# Initialize lists to store the CLingo facts\n",
    "clingo_facts = []\n",
    "\n",
    "# Convert nodes to CLingo facts\n",
    "for node_id in pos:\n",
    "    clingo_facts.append(f'node({node_id}).')\n",
    "\n",
    "# Convert edges to CLingo facts\n",
    "edge_count = min(len(edge_x), len(edge_y))\n",
    "for i in range(edge_count):\n",
    "    source_node = str(node_x[i])\n",
    "    target_node = str(node_y[i])\n",
    "    if source_node not in pos or target_node not in pos:\n",
    "        print(f\"Warning: Source node {source_node} or target node {target_node} is not a valid node.\")\n",
    "        continue\n",
    "    clingo_facts.append(f'edge({source_node}, {target_node}).')\n",
    "\n",
    "# Print the CLingo facts\n",
    "for fact in clingo_facts:\n",
    "    print(fact)\n",
    "\n",
    "# Create the Plotly graph\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x,\n",
    "    y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines'\n",
    ")\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x,\n",
    "    y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='Viridis',\n",
    "        size=10,\n",
    "        colorbar=dict(title='Node ID'),\n",
    "        line_width=2\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a figure and add the traces\n",
    "fig = go.Figure(data=[edge_trace, node_trace])\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    hovermode='closest',\n",
    "    margin=dict(b=20,l=5,r=5,t=40),\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    ")\n",
    "\n",
    "# Plot the graph\n",
    "fig.show()\n",
    "\n",
    "# Example of checking node existence in CLingo facts\n",
    "def check_node_exists(node_id):\n",
    "    return any(fact.startswith(f'node({node_id})') for fact in clingo_facts)\n",
    "\n",
    "print(check_node_exists('1'))  # Should return True\n",
    "print(check_node_exists('5'))  # Should return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02960197-b912-43f7-b3b3-a5ebc03a8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_string(s):\n",
    "    # Normalize the string to NFKD form and encode it to ASCII bytes, ignoring errors\n",
    "    normalized = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')\n",
    "    return normalized\n",
    "\n",
    "# Example usage\n",
    "string = \"è, é, ê, and other accents\"\n",
    "normalized_string = normalize_string(string)\n",
    "print(normalized_string)  # Output: e, e, e, and other accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f2066-be0c-4017-99c3-5f2c73e11aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_asp(graph, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for node, data in graph.nodes(data=True):\n",
    "            line_numbers = data.get('line_numbers', [])\n",
    "            for line in line_numbers:\n",
    "                file.write(f\"node({normalize_string(node).replace('-', '_').replace(' ', '_')}, {int(extract_integers_from_string(line)[0])}).\\n\")\n",
    "                #print(f\"node({normalize_string(node).replace('-', '_').replace(' ', '_')}, {int(extract_integers_from_string(line)[0])}).\\n\")\n",
    "        for node1, node2, data in graph.edges(data=True):\n",
    "            file.write(f\"edge({normalize_string(graph.nodes[node1]['label']).replace('-', '_').replace(' ', '_').lower()}, {normalize_string(graph.nodes[node2]['label']).replace('-', '_').replace(' ', '_').lower()}).\\n\")\n",
    "\n",
    "# Export the combined graph to a .lp file\n",
    "export_to_asp(large_graph, 'graph.lp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
