{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06052175-00a0-4aab-9670-a5d274b30780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function print(*args, sep=' ', end='\\n', file=None, flush=False)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_integers_from_string(s):\n",
    "    # Use regex to find all sequences of digits in the string\n",
    "    integers = re.findall(r'\\d+', str(s))\n",
    "    # Convert the found sequences to integers\n",
    "    return [int(num) for num in integers]\n",
    "\n",
    "# Example usage\n",
    "string = \"50a and 2b, some_text 123\"\n",
    "integers = extract_integers_from_string(string)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d9f24e0-c0b8-4426-a503-5f8819addbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e, e, e, and other accents\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_string(s):\n",
    "    # Normalize the string to NFKD form and encode it to ASCII bytes, ignoring errors\n",
    "    normalized = unicodedata.normalize('NFKD', s).encode('ascii', 'ignore').decode('ascii')\n",
    "    return normalized\n",
    "\n",
    "# Example usage\n",
    "string = \"è, é, ê, and other accents\"\n",
    "normalized_string = normalize_string(string)\n",
    "print(normalized_string)  # Output: e, e, e, and other accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e3e689-d9b6-407b-8627-6a850f2021d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph exported to graph.lp.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create graph from a single CSV file\n",
    "def create_graph_from_csv(file_path, G):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data['sp-tekst-r'] = data['sp-tekst-r'].str.strip().str.lower()\n",
    "    for i in range(len(data)):\n",
    "        node = data.loc[i, 'sp-tekst-r']\n",
    "        line_number = data.loc[i, 'line_number']\n",
    "        if G.has_node(node):\n",
    "            if 'line_numbers' in G.nodes[node]:\n",
    "                if line_number not in G.nodes[node]['line_numbers']:\n",
    "                    G.nodes[node]['line_numbers'].append(line_number)\n",
    "            else:\n",
    "                G.nodes[node]['line_numbers'] = [line_number]\n",
    "        else:\n",
    "            G.add_node(node, pos=(i, data.loc[i, 'sp-km']), line_numbers=[line_number])\n",
    "    for i in range(len(data) - 1):\n",
    "        node1 = data.loc[i, 'sp-tekst-r']\n",
    "        node2 = data.loc[i + 1, 'sp-tekst-r']\n",
    "        dist = data.loc[i + 1, 'sp-km'] - data.loc[i, 'sp-km']\n",
    "        if dist > 0:\n",
    "            G.add_edge(node1, node2, weight=dist)\n",
    "    return G\n",
    "\n",
    "# Initialize the combined graph\n",
    "G_combined = nx.Graph()\n",
    "\n",
    "# Directory containing CSV files\n",
    "csv_directory = 'csv_filtered'\n",
    "\n",
    "# Read each CSV file and update the combined graph\n",
    "for file_name in os.listdir(csv_directory):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(csv_directory, file_name)\n",
    "        try:\n",
    "            G_combined = create_graph_from_csv(file_path, G_combined)\n",
    "        except:\n",
    "            G_combined = G_combined\n",
    "\n",
    "# Export the graph to ASP format\n",
    "def export_to_asp(graph, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for node, data in graph.nodes(data=True):\n",
    "            line_numbers = data.get('line_numbers', [])\n",
    "            for line in line_numbers:\n",
    "                file.write(f\"node({normalize_string(node).replace('-', '_').replace(' ', '_')}, {int(extract_integers_from_string(line)[0])}).\\n\")\n",
    "                #print(f\"node({normalize_string(node).replace('-', '_').replace(' ', '_')}, {int(extract_integers_from_string(line)[0])}).\\n\")\n",
    "        for node1, node2, data in graph.edges(data=True):\n",
    "            weight = data.get('weight', 1)\n",
    "            file.write(f\"edge({normalize_string(node1).replace('-', '_').replace(' ', '_')}, {normalize_string(node2).replace('-', '_').replace(' ', '_')}, {int(weight)}).\\n\")\n",
    "\n",
    "# Export the combined graph to a .lp file\n",
    "export_to_asp(G_combined, 'graph_all_filtered.lp')\n",
    "\n",
    "print(\"Graph exported to graph.lp.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55c4223-f7f1-4fd3-8114-54d4ee0e23b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x21111c79e90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_combined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
